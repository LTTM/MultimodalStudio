<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="MMS-DATA: A Multimodal Multi-view Dataset">
  <meta name="keywords" content="MultimodalStudio, multimodalstudio, NeRFStudio, nerfstudio, SDFStudio, sdfstudio, MMS, mms, multimodal, cvpr 2025, nerf, dataset, infrared, multispectral, polarization">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MMS-DATA: A Multimodal Multi-view Dataset</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="../static/css/bulma.min.css">
  <link rel="stylesheet" href="../static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="../static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="../static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="../static/css/index.css">

  <!--
  <link rel="icon" href="../static/images/favicon.svg">
  -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="../static/js/fontawesome.all.min.js"></script>
  <script src="../static/js/bulma-carousel.min.js"></script>
  <script src="../static/js/bulma-slider.min.js"></script>
  <script src="../static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://lttm.github.io/MultimodalStudio/">
            MultimodalStudio
          </a>
          <a class="navbar-item" href="https://proceedings.bmvc2023.org/571/">
            MP-SDF
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero is-small">
  <div class="hero-body" style="padding-bottom: 1.5rem;">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"><span style="font-size: 1.5em;">MMS-DATA:</span><br>A Multimodal Multi-view Dataset</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://medialab.dei.unipd.it/members/federico-lincetto/">Federico Lincetto</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=Ysz_fQoAAAAJ&hl=en&oi=ao">Gianluca Agresti</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=DA3nSvgAAAAJ&hl=en&oi=ao">Mattia Rossi</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://medialab.dei.unipd.it/members/pietro-zanuttigh/">Pietro Zanuttigh</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup><a href="https://medialab.dei.unipd.it/">Media Lab</a> - University of Padova,</span>
            <span class="author-block"><sup>2</sup>Sony Europe B.V.</span>
          </div>

          <br/>

          <div class="is-size-5 publication-authors">
            <span class="author-block">CVPR 2025</span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <h2 class="title has-text-centered is-3">
            Overview
          </h2>
          <div class="content has-text-justified">
            <p>
              <i>MMS-DATA</i> is a <b>multimodal multi-view calibrated dataset</b> published along with <a style="color: hsl(204, 86%, 53%)" href="https://lttm.github.io/MultimodalStudio/">MultimodalStudio</a>.<br>
              It is captured with 5 different imaging modalities:
            </p>
            <ul>
              <li><b>RGB</b></li>
              <li><b>Monochrome (Mono)</b></li>
              <li><b>Near-infrared (NIR)</b></li>
              <li><b>Polarization (Pol)</b></li>
              <li><b>Multispectral (MS)</b></li>
            </ul>
            <p>
              <i>MMS-DATA</i> includes <b>32 object-centric scenes</b>, with <b>50 viewpoints per scene</b>. The sensor poses are accurately <b>geometrically calibrated</b>.
              The subjects are common objects made from <b>diffusive</b>, <b>glossy</b>, <b>reflective</b>, and <b>transparent materials</b>, such as plastic, metal, wood, organic, cloth, paper, and glass.
              Refer to the paper and to the supplementary material for more details about the dataset and the calibration procedure.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<br>
<br>
<section class="hero teaser">
  <div class="hero-body is-max-desktop">
    <div class="container is-centered" style="max-width: 1800px;">
      <div class="columns is-centered">
        <div class="column">
          <div class="content">
            <div class="content has-text-centered">
              <h2 class="title is-3" style="margin-bottom: 0.1rem">Source Data</h2>
              <p>(35 GB)</p>
            </div>
            <div class="publication-links has-text-centered" style="margin-bottom: 2.5rem">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://medialab.dei.unipd.it/paper_data/MMS-DATA/mms-data_source.zip"
                    class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-download"></i>
                  </span>
                  <span>Download</span>
                </a>
              </span>
            </div>
            <div class="content has-text-justified">
              <p>
                This version of <i>MMS-DATA</i> includes:
              </p>
              <ul>
                <li>the original RAW frames for every modality</li>
                <li>the geometrical camera calibration of all sensors</li>
                <li>the frames used for the camera calibration</li>
                <li>few frames of a color checker</li>
              </ul>
              <p>
                All the frames are RAW, thus they are mosaicked and they did not receive any processing or color correction.
                This version does <b>NOT</b> include the camera poses of every frame.
              </p>
            </div>
          </div>
        </div>
        <div class="column">
          <div class="content">
            <div class="content has-text-centered">
              <h2 class="title is-3" style="margin-bottom: 0.1rem">Processed Raw Data</h2>
              <p>(34 GB)</p>
            </div>
            <div class="publication-links has-text-centered" style="margin-bottom: 2.5rem">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://medialab.dei.unipd.it/paper_data/MMS-DATA/mms-data_raw.zip"
                    class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-download"></i>
                  </span>
                  <span>Download</span>
                </a>
              </span>
            </div>
            <div class="content has-text-justified">
              <p>
                Each scene of this version of <i>MMS-DATA</i> includes:
              </p>
              <ul>
                <li>the processed mosaicked frames</li>
                <li>the metadata of each scene, including camera poses</li>
                <li>a sparse point cloud of the scene</li>
                <li>a point cloud of all the camera positions</li>
              </ul>
              <p>
                All the frames are mosaicked, distorted, and they did not receive any color correction.
                This archive contains the camera pose for all frames of every scene.<br>
                The scenes in this archive are <b>ready-to-use</b> to run MultimodalStudio.
              </p>
            </div>
          </div>
        </div>
        <div class="column">
          <div class="content">
            <div class="content has-text-centered">
              <h2 class="title is-3" style="margin-bottom: 0.1rem">Processed Undistorted Data</h2>
              <p>(128 GB)</p>
            </div>
            <div class="publication-links has-text-centered" style="margin-bottom: 2.5rem">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://medialab.dei.unipd.it/paper_data/MMS-DATA/mms-data_demosaicked_undistorted.zip"
                    class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-download"></i>
                  </span>
                  <span>Download</span>
                </a>
              </span>
            </div>
            <div class="content has-text-justified">
              <p>
                Each scene of this version of <i>MMS-DATA</i> includes:
              </p>
              <ul>
                <li>the demosaicked and undistorted frames</li>
                <li>the metadata of each scene, including camera poses</li>
                <li>a sparse point cloud of the scene</li>
                <li>a point cloud of all the camera positions</li>
              </ul>
              <p>
                All the frames are demosaicked, undistorted, and they did not receive any color correction.
                This archive contains the camera pose for all frames of every scene.<br>
                The scenes in this archive are <b>ready-to-use</b> to run MultimodalStudio.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
  <div class="hero-body ">
    <div class="container is-centered" style="max-width: 1800px; display: flex; justify-content: center;">
      <div class="columns is-centered" style="width: 60%;">
        <div class="column">
          <div class="content">
            <div class="content has-text-centered">
              <h2 class="title is-3" style="margin-bottom: 0.1rem">Sample Scene - Bird House</h2>
              <p>(6 GB)</p>
            </div>
            <div class="publication-links has-text-centered" style="margin-bottom: 2.5rem">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://medialab.dei.unipd.it/paper_data/MMS-DATA/mms-data_birdhouse.zip"
                    class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-download"></i>
                  </span>
                  <span>Download</span>
                </a>
              </span>
            </div>
            <div class="content has-text-justified">
              <p>
                This sample scene of <i>MMS-DATA</i> includes:
              </p>
              <ul>
                <li>the original RAW frames of Bird House</li>
                <li>the geometrical camera calibration of all sensors</li>
                <li>the processed mosaicked frames of Bird House</li>
                <li>the demosaicked and undistorted frames of Bird House</li>
                <li>the metadata of Bird House, including camera poses</li>
                <li>a sparse point cloud of Bird House</li>
                <li>a point cloud of all the camera positions</li>
              </ul>
              <p>
                All the frames did not receive any color correction.
                The Bird House scene in this archive is <b>ready-to-use</b> to run MultimodalStudio.
              </p>
            </div>
          </div>
        </div>
        <div class="column">
          <div class="content">
            <div class="content has-text-centered">
              <h2 class="title is-3" style="margin-bottom: 0.1rem">Distorted Masks</h2>
              <p>(62 MB)</p>
            </div>
            <div class="publication-links has-text-centered" style="margin-bottom: 2.5rem">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://medialab.dei.unipd.it/paper_data/MMS-DATA/mms-data_masks.zip"
                    class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-download"></i>
                  </span>
                  <span>Download</span>
                </a>
              </span>
            </div>
            <div class="content has-text-justified">
              <p>
                This archive includes:
              </p>
              <ul>
                <li>the fore-ground masks for each frame of every modality of every scene</li>
              </ul>
              <p>
                These masks are used to compute the metrics for the tests involving distorted frames.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container has-text-centered">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <img src="../static/images/aloe_cc.jpg"
            class="interpolation-image"
            alt="Aloe"/>
        </div>
        <div class="item item-steve">
          <img src="../static/images/birdhouse_cc.jpg"
            class="interpolation-image"
            alt="Birdhouse"/>
        </div>
        <div class="item item-steve">
          <img src="../static/images/fruits_cc.jpg"
            class="interpolation-image"
            alt="Fruits"/>
        </div>
        <div class="item item-steve">
          <img src="../static/images/chess_cc.jpg"
            class="interpolation-image"
            alt="Chess"/>
        </div>
        <div class="item item-steve">
          <img src="../static/images/toys_cc.jpg"
            class="interpolation-image"
            alt="Toys"/>
        </div>
        <div class="item item-steve">
          <img src="../static/images/steelpot_cc.jpg"
            class="interpolation-image"
            alt="Steelpot"/>
        </div>
        <div class="item item-steve">
          <img src="../static/images/glassclock_cc.jpg"
            class="interpolation-image"
            alt="Glassclock"/>
        </div>
        <div class="item item-steve">
          <img src="../static/images/fan_cc.jpg"
            class="interpolation-image"
            alt="Fan"/>
        </div>
      </div>
    <!--
    <p>
      <i>MMS-DATA</i> scenes preview. It consists of <b>32 object-centric scenes</b> acquired with 5 different imaging modalities: <b>RGB</b>, <b>Monochrome (Mono)</b>, <b>Near Infrared (NIR)</b>, <b>Polarization (Pol)</b> and <b>Multispectral (MS)</b>. The objects are made of diffusive, glossy, reflective, and transparent materials, such as plastic, metal, wood, organic, cloth, paper, and glass.
    </p>
    -->
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Animation. -->
      <div class="column is-full-width">

        <h2 class="title is-3">Multi-sensor Acquisition Setup</h2>
        <table class="is-centered has-text-centered is-fullwidth" style="margin-bottom: 2.5rem">
          <tr>
            <td width="50%" style="padding: 0.75rem;">
              <img src="../static/images/rig_2.jpg"
                   class="interpolation-image"
                   alt="Multi-sensor acquisition setup."/>
            </td>
            <td width="50%" style="padding: 0.75rem;">
              <div class="content has-text-justified">
                <p>
                  The sensors where mounted on a custom-built rig. <br/>
                  We employed <b>5 different imaging sensors</b>:
                    <ul>
                        <li><b>RGB</b>: Basler acA2500-14g</li>
                        <li><b>Monochrome (Mono)</b>: Basler acA2500-14gm</li>
                        <li><b>Near-infrared (NIR)</b>: Basler acA1300-60gmNIR</li>
                        <li><b>Polarization (Pol)</b>:  FLIR BFS-U3-51S5P-C</li>
                        <li><b>Multispectral (MS)</b>: Silios CMS-C1</li>
                    </ul>
                  All the sensors are stereo <b>calibrated</b> with respect to the RGB camera, considered as reference camera.
                </p>
              </div>
            </td>
          </tr>
        </table>

        <h2 class="title is-3">Calibration Results</h2>
        <table class="is-centered has-text-centered is-fullwidth">
          <tr>
            <td width="50%" style="padding: 0.75rem;">
              <img src="../static/images/rmse_calibration.jpg"
                   class="interpolation-image"
                   alt="Calibration RMSE."/>
            </td>
            <td width="50%" style="padding: 0.75rem;">
              <div class="content has-text-justified">
                <p>
                  The calibration process involves two steps:
                </p>
                <ul>
                  <li> the <b>intrinsics</b> calibration,</li>
                  <li>the <b>joint pose calibration</b> of the different sensors</li>
                </ul>
                <p>
                  We calibrated the camera extrinsics assuming a <b>star topology</b>. The RGB sensor is selected as the reference camera,
                  and all the other sensors are stereo calibrated with respect to it.
                </p>
              </div>
            </td>
          </tr>
        </table>

        <h2 class="title is-3">Acquisition Procedure</h2>
        <table class="is-centered has-text-centered is-fullwidth" style="margin-bottom: 2.5rem">
          <tr>
            <td width="50%" style="padding: 0.75rem;">
              <img src="../static/images/acquisition_procedure.jpg"
                   class="interpolation-image"
                   alt="Acquisition procedure."/>
            </td>
            <td width="50%" style="padding: 0.75rem;">
              <div class="content has-text-justified">
                <p>
                  The acquisitions were performed by moving the rig all around the target object placed on the table and by capturing data from <b>all modalities at each viewpoint</b>.
                  The rig was moved manually, therefore the sensor positions are different from scene to scene.<br>
                  The pictures have been acquired by moving the camera rig around the object in <b>2 circular patterns</b>, a lower one and an upper one.
                </p>
              </div>
            </td>
          </tr>
        </table>

    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Materials per scene</h2>
      <img src="../static/images/material_table.jpg"
               class="interpolation-image"
               alt="Table of materials per scene."/>
      <div class="content has-text-centered">
        <p>
          Table of materials per scene. Each scene contains objects made from materials with different properties.
        </p>
      </div>
    </div>
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{lincetto2025multimodalstudio,
  author    = {Lincetto, Federico and Agresti, Gianluca and Rossi, Mattia and Zanuttigh, Pietro},
  title     = {MultimodalStudio: A Heterogeneous Sensor Dataset and Framework for Neural Rendering across Multiple Imaging Modalities},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year      = {2025},
}</code></pre>
  </div>
</section>


<footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This collaborative work was funded by Sony Europe B.V.<br/>
              We warmly thank Piergiorgio Sartor for his brilliant supervision, Francesco Michielin for his help with sensor calibration, and Oliver Erdler, Yalcin Incesu, and Alexander Gatto for their support.
            </p>

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

<script>
  $(window).on('load', function() {
    bulmaCarousel.attach('#results-carousel', {
      slidesToScroll: 1,
      slidesToShow: 3,
      loop: true,
      autoplay: true,
    });
  });
</script>

</body>
</html>
